***

# ОТЧЕТ

## Лабораторная работа №13: Профилирование и оптимизация параллельной программы (MPI + NumPy)

### Сведения о студенте

* **Дата:** 2025-12-28
* **Семестр:** 1
* **Группа:** ПИН-м-о-25-1 (1)
* **Дисциплина:** Параллельные вычисления
* **Студент:** Мизин Глеб Егорович

***

## 1. Цель работы

Выполнить профилирование параллельной программы (MPI) и провести оптимизацию, уменьшающую время выполнения. Сравнить время работы **до** и **после** оптимизации и подтвердить корректность результата.

---

## 2. Исходная задача

В качестве базовой программы использована реализация 2D явной схемы (1D-декомпозиция по `x`, обмен граничными строками между соседями MPI-процессов). Основное вычисление — обновление сетки на каждом шаге времени.

---

## 3. Инструменты профилирования

Использован встроенный профилировщик Python **cProfile** (на `rank 0`), результаты сохранены в файлы:

* `profile_rank0_py_block_p1.txt/.pstats`
* `profile_rank0_vec_block_p1.txt/.pstats`

---

## 4. Найденное узкое место и оптимизация

### Узкое место

В исходном варианте (`kernel=py`) основное время тратится на вычислительное ядро обновления сетки, реализованное **двойными Python-циклами** по узлам.

### Оптимизация

В оптимизированной версии (`kernel=vec`) вычисления переписаны на **векторные операции NumPy** (обновление внутренних узлов делается через срезы массивов). Это резко уменьшает накладные расходы интерпретатора Python.

---

## 5. Параметры эксперимента

* `Nx = 50`, `Ny = 50`
* `M = 500` шагов по времени
* Обмен: `comm=block` (Sendrecv)
* Метрика времени: `compute_time_max` (максимум по процессам)

---

## 6. Команды запуска

```bash
# сравнение на 4 процессах
mpiexec -n 4 python lr13_heat2d_profile_opt.py --kernel py  --comm block --Nx 50 --Ny 50 --M 500
mpiexec -n 4 python lr13_heat2d_profile_opt.py --kernel vec --comm block --Nx 50 --Ny 50 --M 500

# профилирование на 1 процессе (сохранит profile_rank0_*.txt)
mpiexec -n 1 python lr13_heat2d_profile_opt.py --kernel py  --comm block --Nx 50 --Ny 50 --M 500 --profile
mpiexec -n 1 python lr13_heat2d_profile_opt.py --kernel vec --comm block --Nx 50 --Ny 50 --M 500 --profile
```

---

## 7. Результаты

### 7.1. Сравнение времени на p=4

| Вариант      | procs | compute_time_max (s) |     checksum |
| ------------ | ----: | -------------------: | -----------: |
| `kernel=py`  |     4 |             0.705433 | 1.166248e+03 |
| `kernel=vec` |     4 |             0.030697 | 1.166248e+03 |

Ускорение от оптимизации (на p=4):
`Speedup_opt = 0.705433 / 0.030697 ≈ 22.98 раза`

### 7.2. Сравнение времени на p=1 (профилирование)

| Вариант      | procs | compute_time_max (s) |     checksum |
| ------------ | ----: | -------------------: | -----------: |
| `kernel=py`  |     1 |             2.502950 | 1.166248e+03 |
| `kernel=vec` |     1 |             0.043791 | 1.166248e+03 |

Ускорение от оптимизации (на p=1):
`Speedup_opt = 2.502950 / 0.043791 ≈ 57.16 раза`

### 7.3. Корректность

Контрольная сумма `checksum` совпала между версиями, значит оптимизация не изменила результат вычислений.

---

## 8. Вывод

Профилирование показало, что основное время в исходной версии уходит на вычисление обновления сетки, реализованное Python-циклами. После замены вычислений на векторные операции NumPy время выполнения уменьшилось примерно в **23 раза (p=4)** и в **57 раз (p=1)** при сохранении корректности результата (одинаковый `checksum`).

---