***

# ОТЧЕТ

## Лабораторная работа №5: 2D-декомпозиция матрицы и коммуникаторы MPI (Cart/Sub)

### Сведения о студенте

* **Дата:** 2025-12-28
* **Семестр:** 1
* **Группа:** ПИН-м-о-25-1 (1)
* **Дисциплина:** Параллельные вычисления
* **Студент:** Мизин Глеб Егорович

***

## 1. Цель работы

Освоить работу с топологией процессов и подкоммуникаторами MPI, реализовать умножение матрицы на вектор `b = A · x` при **двумерной декомпозиции матрицы** (разбиение по строкам и столбцам) и измерить время выполнения при разном числе процессов.

---

## 2. Постановка задачи

Дана матрица `A` размера `M×N` и вектор `x` длины `N`. Требуется вычислить:

`b = A · x`  (вектор длины `M`)

---

## 3. Идея 2D-декомпозиции

Процессы организуются в двумерную решётку `nrows × ncols` (Cartesian topology).
Матрица `A` разбивается на блоки:

* по строкам: `M` делится между `nrows`
* по столбцам: `N` делится между `ncols`

Каждый процесс с координатами `(row, col)` хранит блок `A_part` размера `M_part × N_part`.

### Распределение вектора x

Вектор `x` разбивается по столбцам (`N_part`) и доставляется всем процессам соответствующего столбца решётки:

1. `Scatterv` по коммуникатору строки (верхняя строка решётки, row=0)
2. `Bcast` вниз по коммуникатору столбца

### Вычисление результата

Каждый процесс вычисляет локальный вклад:

* `b_temp = A_part @ x_part`  (вектор длины `M_part`)

Далее вклады от всех столбцов суммируются **по строке решётки**:

* `Reduce(SUM)` внутри коммуникатора строки → получается `b_part` у процессов `col=0`

После этого `b_part` собирается в итоговый `b` у root:

* `Gatherv` внутри коммуникатора столбца `col=0`

---

## 4. Использованные возможности MPI

* `Create_cart` — создание декартовой топологии процессов
* `Sub` — получение подкоммуникаторов строки и столбца
* `Scatterv` — раздача частей `x` по столбцам
* `Bcast` — рассылка `x_part` вниз по столбцу
* `Reduce(SUM)` — суммирование вкладов `b_temp` по строке
* `Gatherv` — сбор итогового `b` на root
* `Barrier`, `Allreduce(MAX)` — корректное измерение времени (берётся максимум по процессам)

---

## 5. Параметры эксперимента

* `M = 2_000_000`
* `N = 200`

Матрица `A` генерировалась на лету детерминированно (по seed), чтобы не хранить её полностью в памяти. Для проверки печаталась контрольная сумма `checksum` (сумма элементов результата).

---

## 6. Запуск

```bash
mpiexec -n 1 python lr5_2d_matvec.py --M 2000000 --N 200
mpiexec -n 2 python lr5_2d_matvec.py --M 2000000 --N 200
mpiexec -n 4 python lr5_2d_matvec.py --M 2000000 --N 200
mpiexec -n 8 python lr5_2d_matvec.py --M 2000000 --N 200
```

---

## 7. Результаты

### 7.1. Время выполнения

Время — `compute_time_max` (максимум по всем процессам).

| p (процессов) | dims (решётка) | T(p), сек |
| ------------: | -------------- | --------: |
|             1 | 1×1            |  1.475431 |
|             2 | 2×1            |  0.887249 |
|             4 | 2×2            |  0.614151 |
|             8 | 4×2            |  0.493557 |

Контрольная сумма:

* p=1: `9.511078e+07`
* p=2: `9.511078e+07`
* p=4: `9.511043e+07`
* p=8: `9.511043e+07`

(Небольшое отличие на последних разрядах возможно из-за порядка суммирования чисел с плавающей точкой.)

---

### 7.2. Ускорение и эффективность

Формулы:

- `S(p) = T(1) / T(p)`
- `E(p) = S(p) / p`

| p | T(p), сек | Speedup S(p) | Efficiency E(p) |
|--:|----------:|-------------:|----------------:|
| 1 | 1.475431  | 1.000        | 1.000           |
| 2 | 0.887249  | 1.663        | 0.831           |
| 4 | 0.614151  | 2.402        | 0.600           |
| 8 | 0.493557  | 2.989        | 0.374           |

---

## 8. Вывод

Реализовано умножение матрицы на вектор при 2D-декомпозиции данных с использованием:

* декартовой топологии процессов,
* подкоммуникаторов строки/столбца,
* коллективных операций Scatterv/Bcast/Reduce/Gatherv.

Эксперименты показали уменьшение времени при увеличении числа процессов, однако ускорение растёт не линейно из-за накладных расходов обмена данными и синхронизации.

---