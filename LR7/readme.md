***

# ОТЧЕТ

## Лабораторная работа №7: Параллельный метод прогонки (трёхдиагональная СЛАУ) на MPI

### Сведения о студенте

* **Дата:** 2025-12-28
* **Семестр:** 1
* **Группа:** ПИН-м-о-25-1 (1)
* **Дисциплина:** Параллельные вычисления
* **Студент:** Мизин Глеб Егорович

***

## 1. Цель работы

Реализовать параллельный метод решения трёхдиагональной системы линейных уравнений методом прогонки и сравнить время выполнения при разном числе процессов. Проверить корректность результата сравнением с последовательным решением.

---

## 2. Постановка задачи

Решается система `A x = d`, где `A` — трёхдиагональная матрица размера `N×N` с диагоналями:

* нижняя `a`
* главная `b`
* верхняя `c`

Для теста система генерируется так, чтобы было известное решение:

1. генерируется `x_true`
2. вычисляется `d = A · x_true`
3. далее решается `A x = d`

---

## 3. Идея параллельного алгоритма (кратко)

1. Вектор/диагонали разбиваются на блоки по процессам (каждый процесс хранит свой участок трёх диагоналей и RHS).
2. На каждом процессе решаются несколько локальных трёхдиагональных задач методом Томаса (прогонка):

   * `y = A_k^{-1} d_k`
   * `v = A_k^{-1} * [alpha, 0, 0, ...]` (влияние левой границы)
   * `w = A_k^{-1} * [..., 0, gamma]` (влияние правой границы)
3. На root собираются коэффициенты для редуцированной системы размером `2P×2P` (P — число процессов), решается система и получаются граничные значения для каждого блока.
4. Процессы обмениваются граничными значениями с соседями через `Sendrecv`.
5. Каждый процесс восстанавливает своё решение:

   * `x_part = y - v * v_prev - w * u_next`
6. Итоговый `x` собирается на root и сравнивается с последовательным решением и `x_true`.

Использованные MPI операции: `Scatterv`, `Gather/Gatherv`, `Sendrecv`, `Barrier`, `Allreduce(MAX)`.

---

## 4. Параметры эксперимента

* Размер системы: `N = 20000`
* Число процессов: `p = 1, 2, 4, 8`

---

## 5. Команды запуска

```bash
mpiexec -n 1 python lr7_tridiagonal_parallel.py --N 20000
mpiexec -n 2 python lr7_tridiagonal_parallel.py --N 20000
mpiexec -n 4 python lr7_tridiagonal_parallel.py --N 20000
mpiexec -n 8 python lr7_tridiagonal_parallel.py --N 20000
```

---

## 6. Результаты

### 6.1. Время выполнения

`time_parallel_max` — максимальное время по процессам (берём самый медленный процесс).
`time_seq` — время последовательной прогонки на root.

|  p | time_parallel_max (с) | time_seq (с) |
| -: | --------------------: | -----------: |
|  1 |              0.052259 |     0.017140 |
|  2 |              0.025595 |     0.018286 |
|  4 |              0.014118 |     0.017085 |
|  8 |              0.011941 |     0.022279 |

### 6.2. Ускорение и эффективность

Считаем по параллельному времени:

* `Speedup S(p) = T(1) / T(p)`
* `Efficiency E(p) = S(p) / p`

Где `T(1)=0.052259`.

|  p | T(p) (с) | Speedup S(p) | Efficiency E(p) |
| -: | -------: | -----------: | --------------: |
|  1 | 0.052259 |        1.000 |           1.000 |
|  2 | 0.025595 |        2.042 |           1.021 |
|  4 | 0.014118 |        3.702 |           0.925 |
|  8 | 0.011941 |        4.376 |           0.547 |

(Эффективность чуть >1 на p=2 возможна из-за погрешности измерений и различий в накладных расходах/кэше.)

### 6.3. Корректность решения

Сравнение параллельного решения с последовательным и с истинным:

|  p | max|x_par - x_seq| | max|x_par - x_true| |
| -: | -----------------: | ------------------: |
|  1 |          0.000e+00 |           8.882e-16 |
|  2 |          4.441e-16 |           8.882e-16 |
|  4 |          4.441e-16 |           8.882e-16 |
|  8 |          4.441e-16 |           8.882e-16 |

Вывод: результаты совпадают с высокой точностью (ошибка порядка 1e-16).

---

## 7. Заключение

Реализован параллельный метод прогонки для трёхдиагональной СЛАУ. Корректность подтверждена сравнением с последовательным решением и с заранее известным `x_true`. Проведены замеры времени на 1/2/4/8 процессах и рассчитаны ускорение и эффективность.

---